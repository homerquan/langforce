import requests
import base64
import json
import litellm
import os


def call_llm_tool(image, prompt):
    """
    Uses liteLLM to call the model "ollama/llava-llama3" with the provided image and prompt.
    The image (encoded in base64) is sent as an image block in the first user message, and the prompt
    is sent as the second. The output is expected to be a JSON object following a specified schema,
    which includes a "command" field with one of the following values:
    "forward", "backward", "stop", "turn_left", or "turn_right".
    """
    # Convert the image to base64.
    image_base64 = base64.b64encode(image).decode("utf-8")
    # Create a Data URI for the image.
    data_uri = "data:image/jpeg;base64," + image_base64

    # Define the output JSON schema.
    json_schema = {
        "name": "action_demo",
        "schema": {
            "type": "object",
            "properties": {
                "command": {
                    "type": "string",
                    "enum": ["forward", "backward", "stop", "turn_left", "turn_right"],
                    "description": "The navigation command for the robot.",
                }
            },
            "required": ["command"],
        },
    }

    try:
        response = litellm.completion(
            model="ollama/llava-phi3",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": data_uri}},
                    ],
                }
            ],
            response_format={"type": "json_schema", "json_schema": json_schema},
            temperature=0.7,
            max_tokens=15,
            api_base=os.environ.get("OLLAMA_API_BASE", "http://localhost:11434"),
        )
        
        # Debug: print the full response for inspection.
        print("Full response:", response)
        
        # The response should be a JSON object following the json_schema.
        raw_result = response["choices"][0]["message"]["content"]
        if not raw_result or raw_result.strip() == "":
            raise ValueError("Empty response content")
        
        # Parse the JSON string if necessary.
        if isinstance(raw_result, str):
            result = json.loads(raw_result)
        else:
            result = raw_result

        command = result.get("command", "stop")
    except Exception as e:
        print("Error calling LLM tool:", e)
        command = "stop"

    print("Received command:", command)
    return command


def command_to_wheel_speeds(command):
    """
    Maps a textual navigation command to left and right wheel speeds.
    """
    cmd = command.lower()
    if cmd == "forward":
        return (2.0, 2.0)
    elif cmd == "backward":
        return (-2.0, -2.0)
    elif cmd in ["turn left", "turn_left"]:
        return (-1.0, 1.0)
    elif cmd in ["turn right", "turn_right"]:
        return (1.0, -1.0)
    elif cmd == "stop":
        return (0.0, 0.0)
    else:
        return (0.0, 0.0)
